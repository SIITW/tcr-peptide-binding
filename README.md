# TCR-è‚½ç»“åˆé¢„æµ‹ç³»ç»Ÿ

ä¸€ä¸ªç»“æ„åŒ–ã€æ¨¡å—åŒ–çš„TCRï¼ˆTç»†èƒå—ä½“ï¼‰ä¸è‚½ç»“åˆé¢„æµ‹æ·±åº¦å­¦ä¹ ç³»ç»Ÿï¼ŒåŸºäºESM++é¢„è®­ç»ƒè›‹ç™½è´¨è¯­è¨€æ¨¡å‹ã€PEFTå¾®è°ƒæŠ€æœ¯å’ŒCross Attentionæœºåˆ¶ã€‚

## ğŸ¯ é¡¹ç›®ç‰¹è‰²

### æ ¸å¿ƒæŠ€æœ¯æ ˆ
- **é¢„è®­ç»ƒæ¨¡å‹**: ESM++ (Evolutionary Scale Modeling++)
- **å¾®è°ƒæŠ€æœ¯**: æ”¯æŒ7ç§PEFTæ–¹æ³• (LoRA, AdaLoRA, VeRA, BOFT, FourierFT, OFT, IA3)
- **æ³¨æ„åŠ›æœºåˆ¶**: åŒå‘Cross Attentionèåˆ
- **è®­ç»ƒæ¡†æ¶**: PyTorch Lightning
- **é…ç½®ç®¡ç†**: YAMLé…ç½®æ–‡ä»¶ + å‘½ä»¤è¡Œå‚æ•°è¦†ç›–

### æ¨¡å‹æ¶æ„
```
TCRåºåˆ— â”€â”€â”
          â”œâ”€â†’ ESM++ ç¼–ç å™¨ â”€â”€â”
è‚½åºåˆ— â”€â”€â”€â”˜                  â”œâ”€â†’ Cross Attention â”€â”€â†’ åˆ†ç±»å™¨ â”€â”€â†’ ç»“åˆé¢„æµ‹
                            â”˜
            â†“ PEFTå¾®è°ƒ        â†“ åŒå‘æ³¨æ„åŠ›      â†“ æ± åŒ–+èåˆ
          (LoRA/AdaLoRA/...)  (TCRâ†”è‚½ç›¸äº’å…³æ³¨)  (è¿æ¥/è‡ªé€‚åº”)
```

## ğŸ“ é¡¹ç›®ç»“æ„

```
tcr_peptide_binding/
â”œâ”€â”€ configs/                    # é…ç½®æ–‡ä»¶
â”‚   â””â”€â”€ default_config.yaml    # é»˜è®¤é…ç½®ï¼ˆè¯¦ç»†æ³¨é‡Šï¼‰
â”œâ”€â”€ src/                       # æºä»£ç 
â”‚   â”œâ”€â”€ models/               # æ¨¡å‹ç»„ä»¶
â”‚   â”‚   â”œâ”€â”€ encoders.py       # TCRå’Œè‚½ç¼–ç å™¨
â”‚   â”‚   â”œâ”€â”€ attention.py      # Cross Attentionæœºåˆ¶
â”‚   â”‚   â”œâ”€â”€ classifiers.py    # ç»“åˆé¢„æµ‹åˆ†ç±»å™¨
â”‚   â”‚   â””â”€â”€ binding_model.py  # å®Œæ•´æ¨¡å‹ç»„è£…
â”‚   â”œâ”€â”€ data/                 # æ•°æ®å¤„ç†
â”‚   â”‚   â”œâ”€â”€ dataset.py        # æ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨
â”‚   â”‚   â””â”€â”€ preprocessing.py  # æ•°æ®é¢„å¤„ç†å·¥å…·
â”‚   â”œâ”€â”€ training/             # è®­ç»ƒæ¨¡å—
â”‚   â”‚   â””â”€â”€ lightning_module.py # PyTorch Lightningæ¨¡å—
â”‚   â””â”€â”€ utils/                # å·¥å…·å‡½æ•°
â”‚       â”œâ”€â”€ config.py         # é…ç½®ç®¡ç†
â”‚       â”œâ”€â”€ logging_setup.py  # æ—¥å¿—é…ç½®
â”‚       â”œâ”€â”€ paths.py          # è·¯å¾„ç®¡ç†
â”‚       â”œâ”€â”€ reproducibility.py # éšæœºç§å­è®¾ç½®
â”‚       â””â”€â”€ metrics.py        # è¯„ä¼°æŒ‡æ ‡
â”œâ”€â”€ scripts/                  # æ‰§è¡Œè„šæœ¬
â”‚   â””â”€â”€ train.py             # ä¸»è®­ç»ƒè„šæœ¬
â”œâ”€â”€ docs/                    # æ–‡æ¡£
â”œâ”€â”€ tests/                   # æµ‹è¯•
â””â”€â”€ outputs/                 # è¾“å‡ºç›®å½•
    â”œâ”€â”€ checkpoints/         # æ¨¡å‹æ£€æŸ¥ç‚¹
    â”œâ”€â”€ logs/               # è®­ç»ƒæ—¥å¿—
    â”œâ”€â”€ results/            # è¯„ä¼°ç»“æœ
    â””â”€â”€ plots/              # å¯è§†åŒ–å›¾è¡¨
```

## ğŸš€ å¿«é€Ÿå¼€å§‹



### 1. å‡†å¤‡æ•°æ®

æ•°æ®æ ¼å¼ä¸ºCSVæ–‡ä»¶ï¼ŒåŒ…å«ä»¥ä¸‹åˆ—ï¼š
```csv
TCR,Peptide,Label
CASSRTGDNEQFF,KLGGALQAK,1
CASSLGDSEQFF,VLQAGQVVL,0
...
```

### 2. å¼€å§‹è®­ç»ƒ

```bash
# ä½¿ç”¨é»˜è®¤é…ç½®è®­ç»ƒ
python scripts/train.py --data_path data/your_data.csv

# è‡ªå®šä¹‰å‚æ•°è®­ç»ƒ
python scripts/train.py \
    --data_path data/your_data.csv \
    --batch_size 8 \
    --learning_rate 1e-5 \
    --epochs 20 \
    --peft_method lora

# ä½¿ç”¨è‡ªå®šä¹‰é…ç½®æ–‡ä»¶
python scripts/train.py \
    --config configs/my_config.yaml \
    --data_path data/your_data.csv
```

## âš™ï¸ é…ç½®è¯´æ˜



### Cross Attentionç­–ç•¥

- åŒå‘äº¤å‰æ³¨æ„åŠ›
- ç®€å•æœ‰æ•ˆï¼Œè®¡ç®—å¼€é”€å°

### ç¡¬ä»¶é…ç½®å»ºè®®

## ğŸ“Š è®­ç»ƒç›‘æ§

### TensorBoard
```bash
tensorboard --logdir outputs/logs/tensorboard
```

### è®­ç»ƒæŒ‡æ ‡
- **æŸå¤±**: `train_loss`, `val_loss`
- **å‡†ç¡®ç‡**: `train_acc`, `val_acc`
- **F1åˆ†æ•°**: `val_f1`
- **AUCæŒ‡æ ‡**: `val_auroc`, `val_auprc`
- **å­¦ä¹ ç‡**: `learning_rate`

## ğŸ”§ é«˜çº§é…ç½®

### è‡ªå®šä¹‰é…ç½®æ–‡ä»¶

å¤åˆ¶ `configs/default_config.yaml` å¹¶ä¿®æ”¹æ‰€éœ€å‚æ•°ï¼š

```yaml
# æ¨¡å‹é…ç½®
model:
  tokenizer_name: "Synthyra/ESMplusplus_large"

# PEFTé…ç½®
peft:
  method: "adalora"  # ä½¿ç”¨AdaLoRA
  lora_r: 16         # å¢åŠ LoRAç§©
  lora_alpha: 32

# è®­ç»ƒé…ç½®  
training:
  batch_size: 16
  learning_rate: 1e-5
  epochs: 30

# èåˆé…ç½®
fusion:
  type: "enhanced"   # ä½¿ç”¨å¢å¼ºç‰ˆèåˆ
  use_contrastive: true
```

### å‘½ä»¤è¡Œå‚æ•°è¦†ç›–

```bash
python scripts/train.py \
    --config configs/my_config.yaml \
    --batch_size 8 \              # è¦†ç›–é…ç½®æ–‡ä»¶ä¸­çš„batch_size
    --peft_method vera \          # è¦†ç›–PEFTæ–¹æ³•
    --devices 2                   # ä½¿ç”¨2ä¸ªGPU
```

## ğŸ“ˆ ç»“æœåˆ†æ

è®­ç»ƒå®Œæˆåï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨ç”Ÿæˆï¼š

1. **æ¨¡å‹æ£€æŸ¥ç‚¹**: `outputs/checkpoints/`
2. **è®­ç»ƒæ—¥å¿—**: `outputs/logs/`
3. **è¯„ä¼°æŠ¥å‘Š**: `outputs/results/`
4. **å¯è§†åŒ–å›¾è¡¨**: `outputs/plots/`

## ğŸ“š æŠ€æœ¯ç»†èŠ‚

### Cross Attentionæœºåˆ¶

```python
# TCRå…³æ³¨è‚½çš„é‡è¦ä¿¡æ¯
tcr_attended = MultiheadAttention(
    query=tcr_embeddings,      # TCRä½œä¸ºæŸ¥è¯¢
    key=peptide_embeddings,    # è‚½ä½œä¸ºé”®
    value=peptide_embeddings   # è‚½ä½œä¸ºå€¼
)

# è‚½å…³æ³¨TCRçš„é‡è¦ä¿¡æ¯  
peptide_attended = MultiheadAttention(
    query=peptide_embeddings,  # è‚½ä½œä¸ºæŸ¥è¯¢
    key=tcr_embeddings,        # TCRä½œä¸ºé”®
    value=tcr_embeddings       # TCRä½œä¸ºå€¼
)
```
